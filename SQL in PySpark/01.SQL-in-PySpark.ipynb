{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8890948c-57e4-4d61-b258-5b982cec1ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bookings_df = spark.read.table(\"samples.wanderbricks.bookings\")\n",
    "bookings_df.createOrReplaceTempView(\"temp_bookings\")\n",
    "\n",
    "booking_upd_df = spark.read.table(\"samples.wanderbricks.booking_updates\")\n",
    "booking_upd_df.createOrReplaceTempView(\"booking_updates\")\n",
    "\n",
    "click_st_df = spark.read.table(\"samples.wanderbricks.clickstream\")\n",
    "click_st_df.createOrReplaceTempView(\"clickstream\")\n",
    "\n",
    "countries_df = spark.read.table(\"samples.wanderbricks.countries\")\n",
    "countries_df.createOrReplaceTempView(\"countries\")\n",
    "\n",
    "customer_sp_df = spark.read.table(\"samples.wanderbricks.customer_support_logs\")\n",
    "customer_sp_df.createOrReplaceTempView(\"customer_support_logs\")\n",
    "\n",
    "destinations_df = spark.read.table(\"samples.wanderbricks.destinations\")\n",
    "destinations_df.createOrReplaceTempView(\"destinations\")\n",
    "\n",
    "employees_df = spark.read.table(\"samples.wanderbricks.employees\")\n",
    "employees_df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "hosts_df = spark.read.table(\"samples.wanderbricks.hosts\")\n",
    "hosts_df.createOrReplaceTempView(\"hosts\")\n",
    "\n",
    "page_views_df = spark.read.table(\"samples.wanderbricks.page_views\")\n",
    "page_views_df.createOrReplaceTempView(\"page_views\")\n",
    "\n",
    "payments_df = spark.read.table(\"samples.wanderbricks.payments\")\n",
    "payments_df.createOrReplaceTempView(\"payments\")\n",
    "\n",
    "properties_df = spark.read.table(\"samples.wanderbricks.properties\")\n",
    "properties_df.createOrReplaceTempView(\"properties\")\n",
    "\n",
    "property_amenities_df = spark.read.table(\"samples.wanderbricks.property_amenities\")\n",
    "property_amenities_df.createOrReplaceTempView(\"property_amenities\")\n",
    "\n",
    "reviews_df = spark.read.table(\"samples.wanderbricks.reviews\")\n",
    "reviews_df.createOrReplaceTempView(\"reviews\")\n",
    "\n",
    "users_df = spark.read.table(\"samples.wanderbricks.users\")\n",
    "users_df.createOrReplaceTempView(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e5d9ff5-71eb-4c95-8674-e89980a0176e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_list = ['temp_bookings', 'booking_updates', 'clickstream', 'countries', 'customer_support_logs', 'destinations', 'employees', 'hosts', 'page_views', 'payments', 'properties', 'property_amenities', 'reviews', 'users']\n",
    "\n",
    "for table_name in table_list:\n",
    "    sql_query = f\"DESCRIBE {table_name}\"\n",
    "    description_df = spark.sql(sql_query)\n",
    "    print(f\"\\n--- Overlook of {table_name} table---\")\n",
    "    description_df.select('col_name', 'data_type').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "289bbd8a-9de2-44c7-97a4-805fd535bbd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## -> Question1: What are the top 5 destinations with the highest average revenue (per reservation) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b5e9d2e-33a2-40b7-bb75-ce0ab961e2d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_query = \"\"\"\n",
    "                SELECT\n",
    "                        DS.DESTINATION_ID ,\n",
    "                        DS.DESTINATION,\n",
    "                        ROUND( SUM(TB.TOTAL_AMOUNT),2 )  AS TOTAL_REVENUE,\n",
    "                        ROUND( COUNT(DISTINCT TB.BOOKING_ID),0) AS TOTAL_BOOKINGS,\n",
    "                        ROUND((CASE \n",
    "                            COUNT(DISTINCT TB.BOOKING_ID) WHEN 0 THEN 0 \n",
    "                                                        ELSE SUM(TB.TOTAL_AMOUNT) / COUNT(DISTINCT TB.BOOKING_ID) END),2) AVG_REVENUE\n",
    "                        \n",
    "                        FROM temp_bookings TB\n",
    "                        LEFT JOIN properties PR ON PR.property_id = TB.property_id\n",
    "                        LEFT JOIN destinations DS ON DS.destination_id = PR.destination_id\n",
    "                        GROUP BY DS.DESTINATION_ID ,DS.DESTINATION\n",
    "                        HAVING ROUND( COUNT(DISTINCT TB.BOOKING_ID),0) > 5\n",
    "                        ORDER BY AVG_REVENUE DESC\n",
    "                        LIMIT 5\n",
    "\n",
    "            \"\"\"\n",
    "spark.sql(temp_query).show()\n",
    "\n",
    "del temp_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c357b82-4ee1-4898-94a0-bd8af031f014",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## -> Question2: What is the difference between the average ratings and average stay lengths (per night) for houses and apartments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e78a2a7-25ef-42db-a4f0-868e69b30478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_query = \"\"\"\n",
    "                WITH \n",
    "                  PROPERTY_FEATURE AS (SELECT\n",
    "                                                PR.PROPERTY_ID,\n",
    "                                                TB.BOOKING_ID,\n",
    "                                                PR.TITLE,\n",
    "                                                (CASE\n",
    "                                                      WHEN PR.TITLE ILIKE '%apartment%' OR PR.title ILIKE '%flat%' THEN 'Apartment'\n",
    "                                                      WHEN PR.TITLE ILIKE '%house%' OR PR.title ILIKE '%villa%' THEN 'House'\n",
    "                                                      ELSE 'Other' \n",
    "                                                END) AS PROPERTY_CAT,\n",
    "                                                RV.RATING,\n",
    "                                                DATEDIFF(TB.CHECK_OUT, TB.CHECK_IN) AS STAY_LENGTH\n",
    "                                          FROM temp_bookings TB\n",
    "                                                LEFT JOIN properties PR ON PR.property_id = TB.property_id\n",
    "                                                LEFT JOIN reviews RV ON RV.booking_id = TB.booking_id\n",
    "                                          WHERE DATEDIFF(TB.CHECK_OUT, TB.CHECK_IN) > 0 \n",
    "                                                AND RV.RATING IS NOT NULL \n",
    "                                          )\n",
    "                  SELECT\n",
    "                        PF.PROPERTY_CAT,\n",
    "                        ROUND(AVG(PF.RATING),2) AVG_RATE,\n",
    "                        ROUND(AVG(PF.STAY_LENGTH),2) AVG_STAY,\n",
    "                        COUNT(BOOKING_ID) TOTAL_ANALYZED_BOOKINGS\n",
    "                  FROM PROPERTY_FEATURE PF\n",
    "                  WHERE PF.PROPERTY_CAT IN ('Apartment', 'House')\n",
    "                  GROUP BY PF.PROPERTY_CAT\n",
    "                  ORDER BY PROPERTY_CAT \n",
    "\n",
    "              \"\"\"\n",
    "spark.sql(temp_query).show(10)\n",
    "\n",
    "del temp_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c1a7ec1-18f4-4266-8e0f-62d89cbc0fe8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## -> Question3: Sort each user's (user_id) reservations by date and calculate the price difference compared to the user's previous reservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25101119-e2c5-4630-a79b-2aa3961fdbb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_query = \"\"\"\n",
    "                WITH \n",
    "                  COMMON_USER AS (SELECT\n",
    "                                          USER_ID,\n",
    "                                          COUNT(DISTINCT(TB.BOOKING_ID)) FRQ\n",
    "                                    FROM temp_bookings TB\n",
    "                                    WHERE TB.STATUS <> 'cancelled'\n",
    "                                    GROUP BY TB.USER_ID\n",
    "                                    HAVING COUNT(DISTINCT(TB.BOOKING_ID)) > 1\n",
    "                                    ORDER BY FRQ DESC\n",
    "                                    LIMIT 10 \n",
    "                                    )\n",
    "                      \n",
    "                  SELECT\n",
    "                        --TB.USER_ID,\n",
    "                        TB.*,\n",
    "                        LAG(total_amount, 1) OVER (PARTITION BY TB.USER_ID ORDER BY TB.CHECK_IN ASC) PREV_BOOKING_PRICE,\n",
    "                        ROUND((TB.TOTAL_AMOUNT - LAG(TB.TOTAL_AMOUNT, 1) OVER ( PARTITION BY TB.USER_ID ORDER BY TB.CHECK_IN ASC)),2) AS PRICE_DIFFERENCE,\n",
    "\n",
    "                        MAX(ABS(ROUND((TB.TOTAL_AMOUNT - LAG(TB.TOTAL_AMOUNT, 1) OVER ( PARTITION BY TB.USER_ID ORDER BY TB.CHECK_IN ASC)),2)) ) OVER (PARTITION BY TB.USER_ID) AS MAX_DIFFERENCE,\n",
    "                        MIN(ABS(ROUND((TB.TOTAL_AMOUNT - LAG(TB.TOTAL_AMOUNT, 1) OVER ( PARTITION BY TB.USER_ID ORDER BY TB.CHECK_IN ASC)),2)) ) OVER (PARTITION BY TB.USER_ID) AS MIN_DIFFERENCE,\n",
    "                        ROUND( AVG(ABS(ROUND((TB.TOTAL_AMOUNT - LAG(TB.TOTAL_AMOUNT, 1) OVER ( PARTITION BY TB.USER_ID ORDER BY TB.CHECK_IN ASC)),2)) ) OVER (PARTITION BY TB.USER_ID),2) AS AVG_DIFFERENCE\n",
    "                        \n",
    "                        FROM temp_bookings TB\n",
    "                        WHERE TB.USER_ID IN (SELECT USER_ID FROM COMMON_USER )\n",
    "                              AND TB.STATUS <> 'cancelled'\n",
    "                        ORDER BY TB.USER_ID ASC, TB.CHECK_IN\n",
    "            \"\"\"\n",
    "\n",
    "spark.sql(temp_query).show(10)\n",
    "\n",
    "del temp_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563a67b9-da47-4822-aca9-0af2000e4761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## -> Question4: Find the top 10 property owners and display each one's average bathroom/bedroom ratio and average rating in a single result set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28854c8a-846a-4c0b-a33f-9ece78026e64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_query = \"\"\"\n",
    "                WITH WEALTHY_HOSTS AS (SELECT\n",
    "                                                HS.HOST_ID,\n",
    "                                                HS.NAME,\n",
    "                                                COUNT(DISTINCT(PR.PROPERTY_ID)) TOTAL_PROPERTIES\n",
    "                                                FROM hosts HS\n",
    "                                                      LEFT JOIN properties PR ON PR.HOST_ID = HS.HOST_ID\n",
    "                                                      GROUP BY HS.HOST_ID,HS.NAME\n",
    "                                                      ORDER BY TOTAL_PROPERTIES DESC\n",
    "                                                      LIMIT 10\n",
    "                                          ),\n",
    "\n",
    "                  MOST_RATED_PR AS (SELECT property_id,\n",
    "                                          ROUND(AVG(rating), 2) AS avg_property_rating \n",
    "                                    FROM reviews\n",
    "                                    GROUP BY property_id\n",
    "                                    ),\n",
    "                  HOST_PROPERTY_METRICS AS (\n",
    "                                                SELECT WH.HOST_ID,\n",
    "                                                      WH.NAME,\n",
    "                                                      CASE \n",
    "                                                            WHEN PR.bedrooms > 0 THEN ROUND( (CAST(PR.bathrooms AS FLOAT) / PR.bedrooms),2)\n",
    "                                                            ELSE 0.00 \n",
    "                                                      END BATHROOM_TO_BEDROOM_RATIO,\n",
    "                                                      COALESCE(MRP.avg_property_rating,0.00 ) PROPERTY_RATING\n",
    "                                                FROM WEALTHY_HOSTS WH\n",
    "                                                INNER JOIN properties PR ON PR.HOST_ID = WH.HOST_ID\n",
    "                                                INNER JOIN hosts HS ON HS.HOST_ID = WH.HOST_ID\n",
    "                                                LEFT JOIN MOST_RATED_PR MRP ON  MRP.PROPERTY_ID = PR.PROPERTY_ID \n",
    "                                          )\n",
    "\n",
    "                  SELECT\n",
    "                        HPM.HOST_ID,\n",
    "                        HPM.NAME,\n",
    "                        COUNT(*) TOTAL_PROPERTIES_ANALYZED,\n",
    "                        ROUND(AVG( HPM.BATHROOM_TO_BEDROOM_RATIO ),2) AVG_HOST_RATIO,\n",
    "                        ROUND( AVG( HPM.PROPERTY_RATING ) ,2) AVG_HOST_RATING\n",
    "                  FROM HOST_PROPERTY_METRICS HPM\n",
    "                  GROUP BY HPM.HOST_ID,HPM.NAME\n",
    "                  ORDER BY TOTAL_PROPERTIES_ANALYZED DESC\n",
    "                  LIMIT 10\n",
    "                        \n",
    "            \"\"\"\n",
    "\n",
    "spark.sql(temp_query).show()\n",
    "\n",
    "del temp_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f8d6bd9-1f93-4764-9b12-bc5b5a1f23dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## -> Question5: How many events (view, search, click, filter) have occurred? Who are the users with the most events? Which properties receive the most interactions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f16f26fc-ce5c-4537-9c31-591d41752fc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_query = \"\"\"\n",
    "                SELECT\n",
    "                        event,\n",
    "                        COUNT(1) AS total_events\n",
    "                FROM clickstream\n",
    "                GROUP BY event\n",
    "                ORDER BY total_events DESC\n",
    "            \"\"\"\n",
    "\n",
    "spark.sql(temp_query).show()\n",
    "\n",
    "del temp_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9f568ec-4aaf-4c55-ac3f-082c6568cd02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_query = \"\"\"\n",
    "                SELECT\n",
    "                    u.user_id,\n",
    "                    u.name,\n",
    "                    COUNT(c.event) AS total_interactions\n",
    "                FROM clickstream c\n",
    "                INNER JOIN users U ON c.user_id = U.user_id\n",
    "                GROUP BY u.user_id,u.name\n",
    "                ORDER BY total_interactions DESC\n",
    "                LIMIT 10\n",
    "                \"\"\"\n",
    "\n",
    "spark.sql(temp_query).show()\n",
    "\n",
    "del temp_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd6e0c5-0f38-4cc6-9cc6-e33d0ec4fb63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_query = \"\"\"\n",
    "                SELECT\n",
    "                    u.user_id,\n",
    "                    u.name,\n",
    "                    c.event\n",
    "                FROM clickstream c\n",
    "                INNER JOIN users U ON c.user_id = U.user_id\n",
    "                \"\"\"\n",
    "\n",
    "df_user = spark.sql(temp_query)\n",
    "df_user_piv = df_user.groupBy(\"user_id\", \"name\").pivot(\"event\").agg(F.count(\"event\").alias(\"total_interactions\"))\n",
    "df_user_filled = df_user_piv.na.fill(0)\n",
    "user_event_cols = [col for col in df_user_filled.columns if col not in (\"user_id\", \"name\")]\n",
    "sum_expression_user = sum(F.col(col) for col in user_event_cols)\n",
    "df_user_final = df_user_filled.withColumn(\"Row Summary\", sum_expression_user)\n",
    "df_user_final.sort(\"Row Summary\", ascending=False).show(10)\n",
    "del temp_query,df_user, df_user_piv,df_user_filled,user_event_cols,sum_expression_user,df_user_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55113db1-75ef-439a-b24f-97c4449937b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp_query_property = \"\"\"\n",
    "                        SELECT\n",
    "                                PR.property_id,\n",
    "                                PR.title,\n",
    "                                c.event\n",
    "                        FROM clickstream c\n",
    "                            INNER JOIN properties PR ON c.property_id = PR.property_id\n",
    "                        \"\"\"\n",
    "df_property = spark.sql(temp_query_property)\n",
    "df_property_piv = df_property.groupBy(\"property_id\", \"title\").pivot(\"event\").agg(F.count(\"event\").alias(\"total_interactions\"))\n",
    "df_property_filled = df_property_piv.na.fill(0)\n",
    "property_event_cols = [col for col in df_property_filled.columns if col not in (\"property_id\", \"title\")]\n",
    "sum_expression_property = sum(F.col(col) for col in property_event_cols)\n",
    "df_property_final = df_property_filled.withColumn(\"Row Summary\", sum_expression_property)\n",
    "df_property_final.sort(\"Row Summary\", ascending=False).show(10)\n",
    "del temp_query_property,df_property, df_property_piv,df_property_filled,property_event_cols,sum_expression_property,df_property_final"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01.SQL-in-PySpark",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
